{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856519b6-28b0-4654-a198-a8def5c0e108",
   "metadata": {},
   "source": [
    "About the Dataset\n",
    "\n",
    "Context\n",
    "\n",
    "Jamboree has helped thousands of students like you make it to top colleges abroad. Be it GMAT, GRE or SAT, their unique problem-solving methods ensure maximum scores with minimum effort.\n",
    "They recently launched a feature where students/learners can come to their website and check their probability of getting into the IVY league college. This feature estimates the chances of graduate admission from an Indian perspective.\n",
    "\n",
    "Column Profiling:\n",
    "\n",
    "    Serial No. (Unique row ID)\n",
    "    GRE Scores (out of 340)\n",
    "    TOEFL Scores (out of 120)\n",
    "    University Rating (out of 5)\n",
    "    Statement of Purpose and Letter of Recommendation Strength (out of 5)\n",
    "    Undergraduate GPA (out of 10)\n",
    "    Research Experience (either 0 or 1)\n",
    "    Chance of Admit (ranging from 0 to 1)\n",
    "\n",
    "Concept Used:\n",
    "\n",
    "    Exploratory Data Analysis\n",
    "    Linear Regression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a9fa75-0bd7-44b6-8a6b-f0aff3dcb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3113fe0-5d85-4aea-80e4-27cc71eed069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jamboree_dataset=pd.read_csv('Jamboree_Admission.csv')\n",
    "jamboree_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f3de59-27a7-4d7a-86bb-8549718f2d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "jamboree_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b975797b-0c22-4577-add1-df592d5b93ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jamboree_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90357994-0ec8-47a4-a72a-df64a1bb2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "jamboree_dataset.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80561ca4-2f6c-4154-9fed-9d786ea1162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jamboree_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86f4f1-92d3-412c-a3ff-0263772f6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "jamboree_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679efd0-06e4-47eb-b6d7-673dcaeef291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "jamboree_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be578fe0-7549-4245-9935-b64bb0fa17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jamboree_dataset['Serial No.'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0395fb-f85d-415e-80b0-33acbe7a3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=jamboree_dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfdb326-c70f-4d26-a7b9-88981a86828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns='Serial No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e2bd5-537c-46a1-9140-eafaf93c238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46eacd-0c47-4197-9b85-d1e45d4a6c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "plt.title('Visualization on features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e7a4e-f6f5-4850-8636-d0e961bf319a",
   "metadata": {},
   "source": [
    "\n",
    "    1)Exam scores of GRE, TOEFL and CGPA have a high chance of admit\n",
    "    2)While university ranking, rating of SOP and LOR also have an impact on chances of admit, research is the only variable which doesn't have much of an       impact\n",
    "    3)From the scatterplot that the values of university ranking, SOP, LOR and research are not continuous. \n",
    "      We can convert these columns to categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e0c92-d99d-452c-9002-d88c43769bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'LOR ':'LOR',  'Chance of Admit ':'Chance of Admit'},  inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db0b1a-f037-455f-93d1-93e3706ea0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['University Rating','SOP','LOR']]=df[['University Rating','SOP','LOR']].astype('category')\n",
    "df['Research']=df['Research'].astype('bool')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118f955-2705-4846-83ed-173e8da753d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap to analyse corelation between exam scores and Chances of Admit\\\n",
    "df_corr=df.corr(numeric_only=True)\n",
    "sns.heatmap(df_corr,annot=True)\n",
    "plt.title('To display Corelation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8dacd-8bb0-4acd-a4df-bf714733be1e",
   "metadata": {},
   "source": [
    "1)Confirming the inferences from pairplot, the correlation matrix also shows that \n",
    "exam scores (CGPA/GRE/TOEFL) have a strong positive correlation with chance of admit\n",
    "2)The exam scores GRE,TOFEL,CGPA are also highly correlated amongst themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954622b-9370-4513-ad4f-343e5317ae0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boxplots to analyse the relationship between categorical variables and Chance of Admit\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['bool','category']).columns.tolist()\n",
    "plt.figure(figsize=(10,8))\n",
    "i=1\n",
    "for col in cat_cols:\n",
    "  ax = plt.subplot(2,2,i)\n",
    "  sns.boxplot(data = df, x=col, y='Chance of Admit')\n",
    "  plt.title(f\"Impact of {col} on Chance of Admit\", fontsize=10)\n",
    "  plt.xlabel(col)\n",
    "  plt.ylabel('Chance of Admit')\n",
    "  i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6485c0-11b6-4088-b7ef-7ebdfdb34b82",
   "metadata": {},
   "source": [
    "As seen in the pairplot earlier, the categorical variables such as university ranking, \n",
    "research, quality of SOP and LOR also increase the chances of admit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704e437-b767-4f37-9cd0-ed22afdab383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of continuous numerical features\n",
    "numeric_cols = df.select_dtypes(include=['float','int']).columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "i=1\n",
    "for col in numeric_cols:\n",
    "  ax=plt.subplot(2,2,i)\n",
    "  sns.histplot(data=df[col], kde=True)\n",
    "  plt.title(f'Distribution of {col}')\n",
    "  plt.xlabel(col)\n",
    "  plt.ylabel('Count of Students')\n",
    "  i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7ab08-393d-45af-97b7-287ca847cea6",
   "metadata": {},
   "source": [
    "We can see the range of all the numerical attributes:\n",
    "GRE scores are between 290 and 340, with maximum students scoring in the range 310-330\n",
    "TOEFL scores are between 90 and 120, with maximum students scoring around 105\n",
    "CGPA ranges between 7 and 10, with maximum students scoring around 8.5\n",
    "Chance of Admit is a probability percentage between 0 and 1, with maximum students scoring around 70%-75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee856a90-3499-4e04-8ad2-52775e735e8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of categorical variables\n",
    "plt.figure(figsize=(10,8))\n",
    "i=1\n",
    "\n",
    "for col in cat_cols:\n",
    "  ax = plt.subplot(2,2,i)\n",
    "  sns.countplot(x=df[col])\n",
    "  plt.title(f'Distribution of {col}', fontsize=10)\n",
    "  plt.xlabel(col)\n",
    "  plt.ylabel('Count of Students')\n",
    "  i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e16830c-201c-4b17-89fa-bd2ef9612937",
   "metadata": {},
   "source": [
    "It can be observed that the most frequent value of categorical features is as following:\n",
    "* University Rating: 3\n",
    "* SOP: 3.5 & 4\n",
    "* LOR: 3\n",
    "* Research: True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde8e7e-f3bb-4281-9672-11f67babb3ee",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf32cd-401b-42be-a70f-ad11ea545764",
   "metadata": {},
   "source": [
    "Missing Values/Outliers/Duplicates Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e3830-8d72-4fc0-92a6-15c57620ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check for missing values at all columns\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a8a4f-27bd-47c6-846a-5a43f5610074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa2aa8-e5f0-4ca1-88e2-96f6641ddf18",
   "metadata": {},
   "source": [
    "There are no missing values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb6eec-02c9-4295-aae2-57a851af60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers in numerical columns\n",
    "i=1\n",
    "plt.figure(figsize=(10,4))\n",
    "numeric_cols = df.select_dtypes(include=['float','int']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    ax=plt.subplot(1,4,i)\n",
    "    sns.boxplot(df[col])\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(f'Values of {col}')\n",
    "    i+=1\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179ee13-a484-473c-a5a9-6e884a3e945c",
   "metadata": {},
   "source": [
    "It can be observed that there are no outliers in the numeric columns (all the observations are within the whiskers which represent the mimimum and maximum of the range of values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbaa04-65bf-4df2-8887-290ba9bc1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check duplicate value\n",
    "df[df.duplicated()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cec316-43f4-4ad6-acce-361dd0a430bb",
   "metadata": {},
   "source": [
    "There are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b72237-1ef4-4dd6-819d-27c92c526aae",
   "metadata": {},
   "source": [
    "Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0afc1-370e-4f96-ba0f-74314751b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols.remove('Chance of Admit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274487ac-4ecc-41e7-a04e-0167604ccaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[numeric_cols+cat_cols]\n",
    "y=df['Chance of Admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565b428-b0b0-4ee9-8e1a-719275fdd1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83574f27-5b78-415e-917a-d0a235a18789",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112ea98-4bf5-4bb0-a072-8ae77572c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "print(f'Shape of x_train:{x_train.shape}')\n",
    "print(f'Shape of x_test:{x_test.shape}')\n",
    "print(f'Shape of y_train:{y_train.shape}')\n",
    "print(f'Shape of y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb99516-3282-4586-a6c7-1297e949a52e",
   "metadata": {},
   "source": [
    "Label Encoding and Standardisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6a91b-2522-4c54-b4b1-fea77e22174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise a dictionary for label encoders\n",
    "label_encoders={}\n",
    "for col in cat_cols:\n",
    "    label_encoders[col]=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a823f-15a0-4f9d-b3b2-4f031dff767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting encoders to respective columns\n",
    "for col in cat_cols:\n",
    "    label_encoders[col].fit(x[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889ff2d-2250-45c3-a0db-1bd15557be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming categorical data in train and test data\n",
    "for col in cat_cols:\n",
    "    x_train[col]=label_encoders[col].transform(x_train[col])\n",
    "    x_test[col]=label_encoders[col].transform(x_test[col])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9bd9ee-8903-4673-a282-b7e41dd4e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat_encoded=pd.concat([x_train,x_test])\n",
    "x_cat_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cfff3-6f08-4966-82ad-26daf99a86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising object for MinMaxScaler for standardisation\n",
    "scaler_x=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25913c64-4ac2-45a1-9127-6ef9e76b80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting scaler_x to training data\n",
    "scaler_x.fit(x_cat_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d843ad2-de32-419b-8f1a-95da581b6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols=x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca10d8a-b5a6-413c-aea1-4de2e4c3b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming numerical columns of x_train and x_test\n",
    "x_train[all_cols]=scaler_x.transform(x_train[all_cols])\n",
    "x_test[all_cols]=scaler_x.transform(x_test[all_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15571923-e06f-4078-b137-63d64330a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6467091-931e-4062-a7fc-b88059890f86",
   "metadata": {},
   "source": [
    "Base Model Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b9a25-589e-4461-968e-313b92ae3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising object of class Linear Regression\n",
    "model_lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d121daf-e86f-43f5-8763-369537217bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model to training data\n",
    "model_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80538c72-fc55-41b2-be97-fab75cd6c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=model_lr.predict(x_train)\n",
    "y_pred_test=model_lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd634a8-4a44-4f14-a064-2e58d1fd871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model using multiple loss functions\n",
    "def model_evaluation(y_actual, y_forecast, model):\n",
    "  n = len(y_actual)\n",
    "  if len(model.coef_.shape)==1:\n",
    "    p = len(model.coef_)\n",
    "  else:\n",
    "    p = len(model.coef_[0])\n",
    "  MAE = np.round(mean_absolute_error(y_true=y_actual, y_pred=y_forecast),2)\n",
    "  RMSE = np.round(mean_squared_error(y_true=y_actual,\n",
    "                                     y_pred=y_forecast, squared=False),2)\n",
    "  r2 = np.round(r2_score(y_true=y_actual, y_pred=y_forecast),2)\n",
    "  adj_r2 = np.round(1 - ((1-r2)*(n-1)/(n-p-1)),2)\n",
    "  return print(f\"MAE: {MAE}\\nRMSE: {RMSE}\\nR2 Score: {r2}\\nAdjusted R2: {adj_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dc034-e890-463f-90f2-23d15e255b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics of training a data\n",
    "model_evaluation(y_train.values,y_pred_train,model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b06df-636a-49bf-a54b-1bfbea6f49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics for test data\n",
    "model_evaluation(y_test.values,y_pred_test,model_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5481765-dd86-4672-9b82-e303b8e1ced7",
   "metadata": {},
   "source": [
    "Since there is no difference in the loss scores of training and test data, we can conclude that there is no overfitting of the model\n",
    "\n",
    "* Mean Absolute Error of 0.04 shows that on an average, the absolute difference between the actual and predicted values of chance of admit is 4%\n",
    "* Root Mean Square Error of 0.06 means that on an average, the root of squared difference between the actual and predicted values is 6%\n",
    "* R2 Score of 0.82 means that our model captures 82% variance in the data\n",
    "* Adjusted R2 is an extension of R2 which shows how the number of features used changes the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e903476-bc1c-4313-a345-4c6457d7614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea16bf-ccbe-4a09-bc7e-70d603bba6bb",
   "metadata": {},
   "source": [
    "#Testing Assumptions of Linear Regression Model\n",
    "#Multicolinearity Check\n",
    "VIF (Variance Inflation Factor) is a measure that quantifies the severity of multicollinearity in a regression analysis. It assesses how much the variance of the estimated regression coefficient is inflated due to collinearity.\n",
    "\n",
    "The formula for VIF is as follows:\n",
    "\n",
    "VIF(j) = 1 / (1 - R(j)^2)\n",
    "\n",
    "Where:\n",
    "\n",
    "j represents the jth predictor variable.\n",
    "R(j)^2 is the coefficient of determination (R-squared) obtained from regressing the jth predictor variable on all the other predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88687c8-4f91-4332-a868-43ac5c5b7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Variable'] = x_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train.values, i) for i in range(x_train.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0c47a-3ec0-470f-bdf4-5a983f06cba1",
   "metadata": {},
   "source": [
    "We see that almost all the variables (excluding research) have a very high level of colinearity. \n",
    "This was also observed from the correlation heatmap which showed strong positive \n",
    "correlation between GRE score, TOEFL score and CGPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4554256f-84c9-438d-8abc-aa23a7df2a5a",
   "metadata": {},
   "source": [
    "Mean of Residuals\n",
    "The mean of residuals represents the average of residual values in a regression model. \n",
    "Residuals are the discrepancies or errors between the observed values and the values predicted by the regression model.\n",
    "\n",
    "The mean of residuals is useful to assess the overall bias in the regression model.\n",
    "If the mean of residuals is close to zero, it indicates that the model is unbiased on average.\n",
    "However, if the mean of residuals is significantly different from zero,\n",
    "it suggests that the model is systematically overestimating or underestimating the observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d11d3b-6b97-430a-8de5-54537dccc8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test.values - y_pred_test\n",
    "residuals.reshape((-1,))\n",
    "print('Mean of Residuals: ', residuals.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697b158-6a8a-4aef-bf94-1d9febf735e4",
   "metadata": {},
   "source": [
    "Since the mean of residuals is very close to 0, we can say that the model is unbiased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ae988-4a68-4de7-870a-9815fab079bf",
   "metadata": {},
   "source": [
    "Linearity of Variables\n",
    "Linearity of variables refers to the assumption that there is a linear relationship between the independent variables and the dependent variable in a regression model. It means that the effect of the independent variables on the dependent variable is constant across different levels of the independent variables.\n",
    "\n",
    "When we talk about \"no pattern in the residual plot\" in the context of linearity, we are referring to the plot of the residuals (the differences between the observed and predicted values of the dependent variable) against the predicted values or the independent variables.\n",
    "\n",
    "Ideally, in a linear regression model, the residuals should be randomly scattered around zero, without any clear patterns or trends. This indicates that the model captures the linear relationships well and the assumption of linearity is met.\n",
    "\n",
    "If there is a visible pattern in the residual plot, it suggests a violation of the linearity assumption. Common patterns that indicate non-linearity include:\n",
    "\n",
    "    Curved or nonlinear shape: The residuals form a curved or nonlinear pattern instead of a straight line.\n",
    "    U-shaped or inverted U-shaped pattern: The residuals show a U-shape or inverted U-shape, indicating a nonlinear relationship.\n",
    "    Funnel-shaped pattern: The spread of residuals widens or narrows as the predicted values or independent variables change, suggesting heteroscedasticity.\n",
    "    Clustering or uneven spread: The residuals show clustering or uneven spread across different levels of the predicted values or independent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd90af-bf96-491e-8e7e-d068cdf59ffc",
   "metadata": {},
   "source": [
    "If a pattern is observed in the residual plot, it may indicate that the linear regression model \n",
    "is not appropriate, and nonlinear regression or other modeling techniques should be considered. \n",
    "Additionally, transformations of variables, adding interaction terms,\n",
    "or using polynomial terms can sometimes help capture nonlinear relationships and improve linearity in the residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9f427-e2e3-441f-b0fd-c3f1258b4b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = y_pred_test.reshape((-1,)), y=residuals.reshape((-1,)))\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16d8ba-0256-4db8-955a-5a999e75b6bc",
   "metadata": {},
   "source": [
    "Since the residual plot shows no clear pattern or trend in residuals, we can conclude that linearity of variables exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b3e185-1787-44d9-adfe-09ad388fd72c",
   "metadata": {},
   "source": [
    "Homoscedasticity\n",
    "Homoscedasticity refers to the assumption in regression analysis that the variance of the residuals (or errors) should be constant across all levels of the independent variables. In simpler terms, it means that the spread of the residuals should be similar across different values of the predictors.\n",
    "\n",
    "When homoscedasticity is violated, it indicates that the variability of the errors is not consistent across the range of the predictors, which can lead to unreliable and biased regression estimates.\n",
    "\n",
    "To test for homoscedasticity, there are several graphical and statistical methods that you can use:\n",
    "\n",
    "    Residual plot: Plot the residuals against the predicted values or the independent variables. Look for any systematic patterns or trends in the spread of the residuals. If the spread appears to be consistent across all levels of the predictors, then homoscedasticity is likely met.\n",
    "\n",
    "    Scatterplot: If you have multiple independent variables, you can create scatter plots of the residuals against each independent variable separately. Again, look for any patterns or trends in the spread of the residuals.\n",
    "\n",
    "    Breusch-Pagan Test: This is a statistical test for homoscedasticity. It involves regressing the squared residuals on the independent variables and checking the significance of the resulting model. If the p-value is greater than a chosen significance level (e.g., 0.05), it suggests homoscedasticity. However, this test assumes that the errors follow a normal distribution.\n",
    "\n",
    "    Goldfeld-Quandt Test: This test is used when you suspect heteroscedasticity due to different variances in different parts of the data. It involves splitting the data into two subsets based on a specific criterion and then comparing the variances of the residuals in each subset. If the difference in variances is not significant, it suggests homoscedasticity.\n",
    "\n",
    "It's important to note that the visual inspection of plots is often the first step to identify potential violations of homoscedasticity. Statistical tests can provide additional evidence, but they may have assumptions or limitations that need to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6eb91-532d-4d74-b746-ac3e21c7d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of residuals with each independent variable to check for Homoscedasticity\n",
    "plt.figure(figsize=(12,6))\n",
    "i=1\n",
    "for col in x_test.columns[:-1]:\n",
    "  ax = plt.subplot(2,3,i)\n",
    "  sns.scatterplot(x=x_test[col].values.reshape((-1,)), y=residuals.reshape((-1,)))\n",
    "  plt.title(f'Residual Plot with {col}')\n",
    "  plt.xlabel(col)\n",
    "  plt.ylabel('Residual')\n",
    "  i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca1eb0-6eb2-443c-9c36-fe7d1b1b79a5",
   "metadata": {},
   "source": [
    "Since we do not see any significant change in the spread of residuals with respect to change in independent variables, we can conclude that homoscedasticity is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c760c-703d-4b04-8017-05f754b9080f",
   "metadata": {},
   "source": [
    "Normality of Residuals\n",
    "Normality of residuals refers to the assumption that the residuals (or errors) in a statistical model are normally distributed. Residuals are the differences between the observed values and the predicted values from the model.\n",
    "\n",
    "The assumption of normality is important in many statistical analyses because it allows for the application of certain statistical tests and the validity of confidence intervals and hypothesis tests. When residuals are normally distributed, it implies that the errors are random, unbiased, and have consistent variability.\n",
    "\n",
    "To check for the normality of residuals, you can follow these steps:\n",
    "\n",
    "    Residual Histogram: Create a histogram of the residuals and visually inspect whether the shape of the histogram resembles a bell-shaped curve. If the majority of the residuals are clustered around the mean with a symmetric distribution, it suggests normality.\n",
    "\n",
    "    Q-Q Plot (Quantile-Quantile Plot): This plot compares the quantiles of the residuals against the quantiles of a theoretical normal distribution. If the points in the Q-Q plot are reasonably close to the diagonal line, it indicates that the residuals are normally distributed. Deviations from the line may suggest departures from normality.\n",
    "\n",
    "    Shapiro-Wilk Test: This is a statistical test that checks the null hypothesis that the residuals are normally distributed. The Shapiro-Wilk test calculates a test statistic and provides a p-value. If the p-value is greater than the chosen significance level (e.g., 0.05), it suggests that the residuals follow a normal distribution. However, this test may not be reliable for large sample sizes.\n",
    "\n",
    "    Skewness and Kurtosis: Calculate the skewness and kurtosis of the residuals. Skewness measures the asymmetry of the distribution, and a value close to zero suggests normality. Kurtosis measures the heaviness of the tails of the distribution compared to a normal distribution, and a value close to zero suggests similar tail behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8143c925-ec28-41ff-8998-80f2436bc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of Residuals\n",
    "sns.histplot(residuals.reshape((-1,)), kde=True)\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.xlabel('Value of Residuals')\n",
    "plt.ylabel('Count of Residuals')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b273df4-12fe-4287-9849-e5f915ab1d55",
   "metadata": {},
   "source": [
    "The histogram shows that there is a negative skew in the distribution of residuals but it is close to a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2736287-8160-47db-bcaa-d928e78dce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ-Plot of residuals\n",
    "sm.qqplot(residuals.reshape((-1,)))\n",
    "plt.title('QQ Plot of Residuals')\n",
    "plt.ylabel('Residual Quantiles')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44879f1c-e029-49f5-9d4e-2c6655999cea",
   "metadata": {},
   "source": [
    "The QQ plot shows that residuals are slightly deviating from the straight diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c291df-e250-43a8-b3e3-ea5d7e6352f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso and Ridge Regression\n",
    "# Initialising instance of Ridge and Lasso classes\n",
    "model_ridge = Ridge()\n",
    "model_lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300a1fa-9982-4bf7-8c7f-109080ee2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the models to training data\n",
    "model_ridge.fit(x_train, y_train)\n",
    "model_lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2ff93-d788-437d-81c3-055a3cb3fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values for train and test data\n",
    "\n",
    "y_train_ridge = model_ridge.predict(x_train)\n",
    "y_test_ridge = model_ridge.predict(x_test)\n",
    "\n",
    "y_train_lasso = model_lasso.predict(x_train)\n",
    "y_test_lasso = model_lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad632a-10ed-4f27-b587-6196519b5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model Performance\n",
    "print('Ridge Regression Training Accuracy\\n')\n",
    "model_evaluation(y_train.values, y_train_ridge, model_ridge)\n",
    "print('\\n\\nRidge Regression Test Accuracy\\n')\n",
    "model_evaluation(y_test.values, y_test_ridge, model_ridge)\n",
    "print('\\n\\nLasso Regression Training Accuracy\\n')\n",
    "model_evaluation(y_train.values, y_train_lasso, model_lasso)\n",
    "print('\\n\\nLasso Regression Test Accuracy\\n')\n",
    "model_evaluation(y_test.values, y_test_lasso, model_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83ab9a-fcbf-428b-aec5-9a7f35599038",
   "metadata": {},
   "source": [
    "While Linear Regression and Ridge regression have similar scores, Lasso regression has not performed well on both training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ddde2-fb59-4777-a620-b2b4445441ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying Best Model\n",
    "# Actual v/s Predicted values for training data\n",
    "\n",
    "actual_values = y_train.values.reshape((-1,))\n",
    "predicted_values = [y_pred_train.reshape((-1,)), y_train_ridge.reshape((-1,)), y_train_lasso.reshape((-1,))]\n",
    "model = ['Linear Regression', 'Ridge Regression', 'Lasso Regression']\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "i=1\n",
    "for preds in predicted_values:\n",
    "  ax = plt.subplot(1,3,i)\n",
    "  sns.scatterplot(x=actual_values, y=preds)\n",
    "  plt.plot([min(actual_values),max(actual_values)], [min(actual_values),max(actual_values)], 'k--')\n",
    "  plt.xlabel('Actual Values')\n",
    "  plt.ylabel('Predicted Values')\n",
    "  plt.title(model[i-1])\n",
    "  i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3a9c3-fe29-4e08-a090-067e757fd2ae",
   "metadata": {},
   "source": [
    "We can observe that both Linear Regression and Ridge Regression have similar accuracy while Lasso regression has oversimplified the model.\n",
    "\n",
    "This is the reason that the r2 score of Lasso regression is 0. It doesn't capture any variance in the target variable. It has predicted the same value across all instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a2d65-cff3-4899-9a82-868bb2c39dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Insights & Recommendations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
